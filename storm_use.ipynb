{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_storm.lm import OpenAIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_storm.rm import YouRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_configs = STORMWikiLMConfigs()\n",
    "openai_kwargs = {\n",
    "    'api_key': os.getenv(\"OPENAI_API_KEY\"),\n",
    "    'temperature': 1.0,\n",
    "    'top_p': 0.9,\n",
    "}\n",
    "# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.\n",
    "# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.\n",
    "# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.\n",
    "gpt_35 = OpenAIModel(model='gpt-3.5-turbo', max_tokens=500, **openai_kwargs)\n",
    "gpt_4 = OpenAIModel(model='gpt-4o', max_tokens=3000, **openai_kwargs)\n",
    "lm_configs.set_conv_simulator_lm(gpt_35)\n",
    "lm_configs.set_question_asker_lm(gpt_35)\n",
    "lm_configs.set_outline_gen_lm(gpt_4)\n",
    "lm_configs.set_article_gen_lm(gpt_4)\n",
    "lm_configs.set_article_polish_lm(gpt_4)\n",
    "# Check out the STORMWikiRunnerArguments class for more configurations.\n",
    "engine_args = STORMWikiRunnerArguments(...)\n",
    "rm = YouRM(ydc_api_key=os.getenv('YDC_API_KEY'), k=engine_args.search_top_k)\n",
    "runner = STORMWikiRunner(engine_args, lm_configs, rm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
